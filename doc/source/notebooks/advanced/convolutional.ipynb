{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Gaussian Processes\n",
    "Mark van der Wilk (July 2019)\n",
    "\n",
    "Here we show a simple example of the rectangles experiment, where we compare a normal squared exponential GP, and a convolutional GP. This is similar to the experiment in [1].\n",
    "\n",
    "[1] Van der Wilk, Rasmussen, Hensman (2017). Convolutional Gaussian Processes. *Advances in Neural Information Processing Systems 30*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "Generate a simple dataset of rectangles. We want to classify whether they are tall or wide. **NOTE:** Here we take care to make sure that the rectangles don't touch the edge, which is different to the original paper. We do this to avoid needing to use patch weights, which are needed to correctly account for edge effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import os\n",
    "\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-4)\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "def is_continuous_integration():\n",
    "    return os.environ.get('CI', None) is not None\n",
    "\n",
    "MAXITER = 2 if is_continuous_integration() else 100\n",
    "NUM_TRAIN_DATA = 5 if is_continuous_integration() else 100  # This is less than in the original rectangles dataset\n",
    "NUM_TEST_DATA = 7 if is_continuous_integration() else 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rectangle(arr, x0, y0, x1, y1):\n",
    "    arr[y0:y1, x0] = 1\n",
    "    arr[y0:y1, x1] = 1\n",
    "    arr[y0, x0:x1] = 1\n",
    "    arr[y1, x0:x1+1] = 1\n",
    "    \n",
    "def make_random_rectangle(arr):\n",
    "    x0 = np.random.randint(1, arr.shape[1] - 3)\n",
    "    y0 = np.random.randint(1, arr.shape[0] - 3)\n",
    "    x1 = np.random.randint(x0 + 2, arr.shape[1] - 1)\n",
    "    y1 = np.random.randint(y0 + 2, arr.shape[0] - 1)\n",
    "    make_rectangle(arr, x0, y0, x1, y1)\n",
    "    return x0, y0, x1, y1\n",
    "    \n",
    "def make_rectangles_dataset(num, w, h):\n",
    "    d, Y = np.zeros((num, h, w)), np.zeros((num, 1))\n",
    "    for i, img in enumerate(d):\n",
    "        for j in range(1000):  # Finite number of tries\n",
    "            x0, y0, x1, y1 = make_random_rectangle(img)\n",
    "            rw, rh = y1 - y0, x1 - x0\n",
    "            if rw == rh:\n",
    "                img[:, :] = 0\n",
    "                continue\n",
    "            Y[i, 0] = rw > rh\n",
    "            break\n",
    "    return d.reshape(num, w * h).astype(gpflow.config.default_float()), Y.astype(gpflow.config.default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data = make_rectangles_dataset(NUM_TRAIN_DATA, 28, 28)\n",
    "Xt, Yt = test_data = make_rectangles_dataset(NUM_TEST_DATA, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(X[i, :].reshape(28, 28))\n",
    "    plt.title(Y[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squared Exponential kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_m = gpflow.models.SVGP(gpflow.kernels.SquaredExponential(), gpflow.likelihoods.Bernoulli(),\n",
    "                           gpflow.inducing_variables.InducingPoints(X.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF elbo before training: -4.9704e+00\n"
     ]
    }
   ],
   "source": [
    "rbf_m_log_likelihood = rbf_m.log_likelihood\n",
    "print(\"RBF elbo before training: %.4e\" % rbf_m_log_likelihood(data))\n",
    "rbf_m_log_likelihood = tf.function(rbf_m_log_likelihood, autograph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.280 iter/s\n"
     ]
    }
   ],
   "source": [
    "gpflow.utilities.set_trainable(rbf_m.inducing_variable, False)\n",
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -rbf_m_log_likelihood(data),\n",
    "    variables=rbf_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 100.0%\n",
      "Test acc : 71.42857142857143%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF elbo after training: -3.4740e+00\n"
     ]
    }
   ],
   "source": [
    "train_err = np.mean((rbf_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((rbf_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"RBF elbo after training: %.4e\" % rbf_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5d0003b867e4>:2: AffineScalar.__init__ (from tensorflow_probability.python.bijectors.affine_scalar) is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`AffineScalar` bijector is deprecated; please use `tfb.Shift(loc)(tfb.Scale(...))` instead.\n"
     ]
    }
   ],
   "source": [
    "f64 = lambda x: np.array(x, dtype=np.float64)\n",
    "positive_with_min = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4))(tfp.bijectors.Softplus())\n",
    "constrained = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4), scale=f64(100.0))(tfp.bijectors.Sigmoid())\n",
    "max_abs_1 = lambda: tfp.bijectors.AffineScalar(shift=f64(-2.0), scale=f64(4.0))(tfp.bijectors.Sigmoid())\n",
    "\n",
    "conv_k = gpflow.kernels.Convolutional(gpflow.kernels.SquaredExponential(), [28, 28], [3, 3])\n",
    "conv_k.basekern.lengthscale = gpflow.Parameter(1.0, transform=positive_with_min())\n",
    "# Weight scale and variance are non-identifiable. We also need to prevent variance from shooting off crazily.\n",
    "conv_k.basekern.variance = gpflow.Parameter(1.0, transform=constrained())\n",
    "conv_k.weights = gpflow.Parameter(conv_k.weights.numpy(), transform=max_abs_1())\n",
    "conv_f = gpflow.inducing_variables.InducingPatches(np.unique(conv_k.get_patches(X).numpy().reshape(-1, 9), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_m = gpflow.models.SVGP(conv_k, gpflow.likelihoods.Bernoulli(), conv_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.utilities.set_trainable(conv_m.inducing_variable, False)\n",
    "conv_m.kernel.basekern.variance.trainable = False\n",
    "conv_m.kernel.weights.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv elbo before training: -4.5422e+00\n"
     ]
    }
   ],
   "source": [
    "conv_m_log_likelihood = conv_m.log_likelihood\n",
    "print(\"conv elbo before training: %.4e\" % conv_m_log_likelihood(data))\n",
    "conv_m_log_likelihood = tf.function(conv_m_log_likelihood, autograph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.273 iter/s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m_log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER / 10})\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 60.0%\n",
      "Test acc : 28.57142857142857%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv elbo after training: -3.8623e+00\n"
     ]
    }
   ],
   "source": [
    "conv_m.kernel.basekern.variance.trainable = True\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m.log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "train_err = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.4e\" % conv_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 60.0%\n",
      "Test acc : 28.57142857142857%\n",
      "conv elbo after training: -3.7721e+00\n"
     ]
    }
   ],
   "source": [
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m.log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "train_err = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.4e\" % conv_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 60.0%\n",
      "Test acc : 28.57142857142857%\n",
      "conv elbo after training: -3.6791e+00\n"
     ]
    }
   ],
   "source": [
    "conv_m.kernel.weights.trainable = True\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m.log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "train_err = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.4e\" % conv_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                    </th><th>class    </th><th>transform     </th><th>prior  </th><th>trainable  </th><th>shape    </th><th>dtype  </th><th>value                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SVGP.kernel.variance    </td><td>Parameter</td><td>Softplus      </td><td>       </td><td>True       </td><td>()       </td><td>float64</td><td>0.7567074450843208                                  </td></tr>\n",
       "<tr><td>SVGP.kernel.lengthscale </td><td>Parameter</td><td>Softplus      </td><td>       </td><td>True       </td><td>()       </td><td>float64</td><td>1.0                                                 </td></tr>\n",
       "<tr><td>SVGP.inducing_variable.Z</td><td>Parameter</td><td>              </td><td>       </td><td>False      </td><td>(5, 784) </td><td>float64</td><td>[[0., 0., 0....                                     </td></tr>\n",
       "<tr><td>SVGP.q_mu               </td><td>Parameter</td><td>              </td><td>       </td><td>True       </td><td>(5, 1)   </td><td>float64</td><td>[[0.48861799...                                     </td></tr>\n",
       "<tr><td>SVGP.q_sqrt             </td><td>Parameter</td><td>FillTriangular</td><td>       </td><td>True       </td><td>(1, 5, 5)</td><td>float64</td><td>[[[8.41645245e-01, 0.00000000e+00, 0.00000000e+00...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpflow.utilities.print_summary(rbf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                            </th><th>class    </th><th>transform              </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SVGP.kernel.basekern.variance   </td><td>Parameter</td><td>Sigmoid + AffineScalar </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.2839673466384849                                  </td></tr>\n",
       "<tr><td>SVGP.kernel.basekern.lengthscale</td><td>Parameter</td><td>Softplus + AffineScalar</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.8273819843802804                                  </td></tr>\n",
       "<tr><td>SVGP.kernel.weights             </td><td>Parameter</td><td>Sigmoid + AffineScalar </td><td>       </td><td>True       </td><td>(676,)     </td><td>float64</td><td>[0.99898616, 0.99898616, 0.99898616...              </td></tr>\n",
       "<tr><td>SVGP.inducing_variable.Z        </td><td>Parameter</td><td>                       </td><td>       </td><td>False      </td><td>(35, 9)    </td><td>float64</td><td>[[0., 0., 0....                                     </td></tr>\n",
       "<tr><td>SVGP.q_mu                       </td><td>Parameter</td><td>                       </td><td>       </td><td>True       </td><td>(35, 1)    </td><td>float64</td><td>[[0.33828754...                                     </td></tr>\n",
       "<tr><td>SVGP.q_sqrt                     </td><td>Parameter</td><td>FillTriangular         </td><td>       </td><td>True       </td><td>(1, 35, 35)</td><td>float64</td><td>[[[7.99948148e-01, 0.00000000e+00, 0.00000000e+00...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpflow.utilities.print_summary(conv_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The convolutional kernel performs much better in this simple task. It demonstrates non-local generalization of the strong assumptions in the kernel."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.pct.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
