{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Gaussian Processes\n",
    "Mark van der Wilk (July 2019)\n",
    "\n",
    "Here we show a simple example of the rectangles experiment, where we compare a normal squared exponential GP, and a convolutional GP. This is similar to the experiment in [1].\n",
    "\n",
    "[1] Van der Wilk, Rasmussen, Hensman (2017). Convolutional Gaussian Processes. *Advances in Neural Information Processing Systems 30*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset\n",
    "Generate a simple dataset of rectangles. We want to classify whether they are tall or wide. **NOTE:** Here we take care to make sure that the rectangles don't touch the edge, which is different to the original paper. We do this to avoid needing to use patch weights, which are needed to correctly account for edge effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gpflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import time\n",
    "import os\n",
    "\n",
    "gpflow.config.set_default_float(np.float64)\n",
    "gpflow.config.set_default_jitter(1e-4)\n",
    "gpflow.config.set_default_summary_fmt(\"notebook\")\n",
    "\n",
    "def is_continuous_integration():\n",
    "    return os.environ.get('CI', None) is not None\n",
    "\n",
    "MAXITER = 2 if is_continuous_integration() else 100\n",
    "NUM_TRAIN_DATA = 5 if is_continuous_integration() else 100  # This is less than in the original rectangles dataset\n",
    "NUM_TEST_DATA = 7 if is_continuous_integration() else 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rectangle(arr, x0, y0, x1, y1):\n",
    "    arr[y0:y1, x0] = 1\n",
    "    arr[y0:y1, x1] = 1\n",
    "    arr[y0, x0:x1] = 1\n",
    "    arr[y1, x0:x1+1] = 1\n",
    "    \n",
    "def make_random_rectangle(arr):\n",
    "    x0 = np.random.randint(1, arr.shape[1] - 3)\n",
    "    y0 = np.random.randint(1, arr.shape[0] - 3)\n",
    "    x1 = np.random.randint(x0 + 2, arr.shape[1] - 1)\n",
    "    y1 = np.random.randint(y0 + 2, arr.shape[0] - 1)\n",
    "    make_rectangle(arr, x0, y0, x1, y1)\n",
    "    return x0, y0, x1, y1\n",
    "    \n",
    "def make_rectangles_dataset(num, w, h):\n",
    "    d, Y = np.zeros((num, h, w)), np.zeros((num, 1))\n",
    "    for i, img in enumerate(d):\n",
    "        for j in range(1000):  # Finite number of tries\n",
    "            x0, y0, x1, y1 = make_random_rectangle(img)\n",
    "            rw, rh = y1 - y0, x1 - x0\n",
    "            if rw == rh:\n",
    "                img[:, :] = 0\n",
    "                continue\n",
    "            Y[i, 0] = rw > rh\n",
    "            break\n",
    "    return d.reshape(num, w * h).astype(gpflow.config.default_float()), Y.astype(gpflow.config.default_float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data = make_rectangles_dataset(NUM_TRAIN_DATA, 28, 28)\n",
    "Xt, Yt = test_data = make_rectangles_dataset(NUM_TEST_DATA, 28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x216 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 3))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    plt.imshow(X[i, :].reshape(28, 28))\n",
    "    plt.title(Y[i, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Squared Exponential kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_m = gpflow.models.SVGP(gpflow.kernels.SquaredExponential(), gpflow.likelihoods.Bernoulli(),\n",
    "                           gpflow.inducing_variables.InducingPoints(X.copy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF elbo before training: -4.9704e+00\n"
     ]
    }
   ],
   "source": [
    "rbf_m_log_likelihood = rbf_m.log_likelihood\n",
    "print(\"RBF elbo before training: %.4e\" % rbf_m_log_likelihood(data))\n",
    "rbf_m_log_likelihood = tf.function(rbf_m_log_likelihood, autograph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5b8da862f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5b8da862f0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.786 iter/s\n"
     ]
    }
   ],
   "source": [
    "gpflow.utilities.set_trainable(rbf_m.inducing_variable, False)\n",
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -rbf_m_log_likelihood(data),\n",
    "    variables=rbf_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 100.0%\n",
      "Test acc : 42.857142857142854%\n",
      "RBF elbo after training: -3.4740e+00\n"
     ]
    }
   ],
   "source": [
    "train_err = np.mean((rbf_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((rbf_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"RBF elbo after training: %.4e\" % rbf_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-5d0003b867e4>:2: AffineScalar.__init__ (from tensorflow_probability.python.bijectors.affine_scalar) is deprecated and will be removed after 2020-01-01.\n",
      "Instructions for updating:\n",
      "`AffineScalar` bijector is deprecated; please use `tfb.Shift(loc)(tfb.Scale(...))` instead.\n"
     ]
    }
   ],
   "source": [
    "f64 = lambda x: np.array(x, dtype=np.float64)\n",
    "positive_with_min = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4))(tfp.bijectors.Softplus())\n",
    "constrained = lambda: tfp.bijectors.AffineScalar(shift=f64(1e-4), scale=f64(100.0))(tfp.bijectors.Sigmoid())\n",
    "max_abs_1 = lambda: tfp.bijectors.AffineScalar(shift=f64(-2.0), scale=f64(4.0))(tfp.bijectors.Sigmoid())\n",
    "\n",
    "conv_k = gpflow.kernels.Convolutional(gpflow.kernels.SquaredExponential(), [28, 28], [3, 3])\n",
    "conv_k.basekern.lengthscale = gpflow.Parameter(1.0, transform=positive_with_min())\n",
    "# Weight scale and variance are non-identifiable. We also need to prevent variance from shooting off crazily.\n",
    "conv_k.basekern.variance = gpflow.Parameter(1.0, transform=constrained())\n",
    "conv_k.weights = gpflow.Parameter(conv_k.weights.numpy(), transform=max_abs_1())\n",
    "conv_f = gpflow.inducing_variables.InducingPatches(np.unique(conv_k.get_patches(X).numpy().reshape(-1, 9), axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_m = gpflow.models.SVGP(conv_k, gpflow.likelihoods.Bernoulli(), conv_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpflow.utilities.set_trainable(conv_m.inducing_variable, False)\n",
    "conv_m.kernel.basekern.variance.trainable = False\n",
    "conv_m.kernel.weights.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv elbo before training: -4.6806e+00\n"
     ]
    }
   ],
   "source": [
    "conv_m_log_likelihood = conv_m.log_likelihood\n",
    "print(\"conv elbo before training: %.4e\" % conv_m_log_likelihood(data))\n",
    "conv_m_log_likelihood = tf.function(conv_m_log_likelihood, autograph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5abb8a0268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5abb8a0268> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.943 iter/s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m_log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER / 10})\n",
    "print(f\"{res.nfev / (time.time() - start_time):.3f} iter/s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5abde72c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5abde72c80> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 80.0%\n",
      "Test acc : 42.857142857142854%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv elbo after training: -3.3743e+00\n"
     ]
    }
   ],
   "source": [
    "conv_m.kernel.basekern.variance.trainable = True\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m.log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "train_err = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.4e\" % conv_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5aa87daea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5aa87daea0> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 80.0%\n",
      "Test acc : 42.857142857142854%\n",
      "conv elbo after training: -3.3603e+00\n"
     ]
    }
   ],
   "source": [
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m.log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "train_err = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.4e\" % conv_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5aa8302bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: AutoGraph could not transform <function Scipy.eval_func.<locals>._tf_eval at 0x7f5aa8302bf8> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module 'gast' has no attribute 'Num'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train acc: 80.0%\n",
      "Test acc : 42.857142857142854%\n",
      "conv elbo after training: -3.3542e+00\n"
     ]
    }
   ],
   "source": [
    "conv_m.kernel.weights.trainable = True\n",
    "res = gpflow.optimizers.Scipy().minimize(\n",
    "    lambda: -conv_m.log_likelihood(data),\n",
    "    variables=conv_m.trainable_variables,\n",
    "    method=\"l-bfgs-b\",\n",
    "    options={\"disp\": True, \"maxiter\": MAXITER})\n",
    "train_err = np.mean((conv_m.predict_y(X)[0] > 0.5).numpy().astype('float') == Y)\n",
    "test_err = np.mean((conv_m.predict_y(Xt)[0] > 0.5).numpy().astype('float') == Yt)\n",
    "print(f\"Train acc: {train_err * 100}%\\nTest acc : {test_err*100}%\")\n",
    "print(\"conv elbo after training: %.4e\" % conv_m_log_likelihood(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                    </th><th>class    </th><th>transform     </th><th>prior  </th><th>trainable  </th><th>shape    </th><th>dtype  </th><th>value                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SVGP.kernel.variance    </td><td>Parameter</td><td>Softplus      </td><td>       </td><td>True       </td><td>()       </td><td>float64</td><td>0.7567074451417881                                  </td></tr>\n",
       "<tr><td>SVGP.kernel.lengthscale </td><td>Parameter</td><td>Softplus      </td><td>       </td><td>True       </td><td>()       </td><td>float64</td><td>1.000000001928902                                   </td></tr>\n",
       "<tr><td>SVGP.inducing_variable.Z</td><td>Parameter</td><td>              </td><td>       </td><td>False      </td><td>(5, 784) </td><td>float64</td><td>[[0., 0., 0....                                     </td></tr>\n",
       "<tr><td>SVGP.q_mu               </td><td>Parameter</td><td>              </td><td>       </td><td>True       </td><td>(5, 1)   </td><td>float64</td><td>[[-0.48861799...                                    </td></tr>\n",
       "<tr><td>SVGP.q_sqrt             </td><td>Parameter</td><td>FillTriangular</td><td>       </td><td>True       </td><td>(1, 5, 5)</td><td>float64</td><td>[[[8.41645245e-01, 0.00000000e+00, 0.00000000e+00...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpflow.utilities.print_summary(rbf_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>name                            </th><th>class    </th><th>transform              </th><th>prior  </th><th>trainable  </th><th>shape      </th><th>dtype  </th><th>value                                               </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>SVGP.kernel.basekern.variance   </td><td>Parameter</td><td>Sigmoid + AffineScalar </td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.8171036836716845                                  </td></tr>\n",
       "<tr><td>SVGP.kernel.basekern.lengthscale</td><td>Parameter</td><td>Softplus + AffineScalar</td><td>       </td><td>True       </td><td>()         </td><td>float64</td><td>0.9566901313541412                                  </td></tr>\n",
       "<tr><td>SVGP.kernel.weights             </td><td>Parameter</td><td>Sigmoid + AffineScalar </td><td>       </td><td>True       </td><td>(676,)     </td><td>float64</td><td>[0.99991478, 0.99991478, 0.99991478...              </td></tr>\n",
       "<tr><td>SVGP.inducing_variable.Z        </td><td>Parameter</td><td>                       </td><td>       </td><td>False      </td><td>(39, 9)    </td><td>float64</td><td>[[0., 0., 0....                                     </td></tr>\n",
       "<tr><td>SVGP.q_mu                       </td><td>Parameter</td><td>                       </td><td>       </td><td>True       </td><td>(39, 1)    </td><td>float64</td><td>[[-6.90472731e-01...                                </td></tr>\n",
       "<tr><td>SVGP.q_sqrt                     </td><td>Parameter</td><td>FillTriangular         </td><td>       </td><td>True       </td><td>(1, 39, 39)</td><td>float64</td><td>[[[6.16638269e-01, 0.00000000e+00, 0.00000000e+00...</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpflow.utilities.print_summary(conv_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "The convolutional kernel performs much better in this simple task. It demonstrates non-local generalization of the strong assumptions in the kernel."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,.pct.py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
